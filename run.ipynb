{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv11-seg LGG MRI – FINAL WORKING VERSION\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 1: Fix everything in one go (NO libGL error, NO torch conflict)\n",
        "!pip install -q --force-reinstall --no-cache-dir \\\n",
        "    torch==2.4.1 torchvision==0.19.1 torchaudio==2.4.1 \\\n",
        "    --index-url https://download.pytorch.org/whl/cu118\n",
        "\n",
        "!pip install -q --force-reinstall --no-cache-dir \\\n",
        "    ultralytics kaggle tqdm\n",
        "\n",
        "# OpenCV headless = no libGL error EVER\n",
        "!pip install -q --force-reinstall --no-cache-dir opencv-python-headless==4.10.0.84\n",
        "\n",
        "import torch\n",
        "from IPython.display import FileLink, display, clear_output\n",
        "import os, cv2, numpy as np, random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"All packages fixed & installed!\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "print(f\"GPU: {torch.cuda.get_device_name(0) if torch.cuda.is_available() else 'Not found'}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 2: Upload kaggle.json (drag & drop)\n",
        "print(\"Please DRAG & DROP kaggle.json into the left file panel\")\n",
        "print(\"Then run this cell again\")\n",
        "\n",
        "clear_output(wait=True)\n",
        "\n",
        "if not os.path.exists(\"kaggle.json\"):\n",
        "    print(\"kaggle.json not found! Please upload it.\")\n",
        "else:\n",
        "    !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(\"kaggle.json ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 3: Download dataset\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation -p data --unzip\n",
        "print(\"Dataset downloaded!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 4: Convert to YOLO format\n",
        "raw = Path(\"data/lgg-mri-segmentation\")\n",
        "yolo = Path(\"yolo_dataset\")\n",
        "for p in [\"images/train\",\"images/val\",\"labels/train\",\"labels/val\"]:\n",
        "    (yolo/p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pairs = []\n",
        "for patient in raw.iterdir():\n",
        "    if patient.is_dir():\n",
        "        for img in patient.glob(\"*[0-9].tif\"):\n",
        "            mask = patient / f\"{img.stem}_mask.tif\"\n",
        "            if mask.exists():\n",
        "                pairs.append((img, mask))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(pairs)\n",
        "split = int(0.8 * len(pairs))\n",
        "\n",
        "def convert(img_path, mask_path, split_folder):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    mask = cv2.imread(str(mask_path), 0)\n",
        "    h, w = img.shape[:2]\n",
        "    name = f\"{img_path.parent.name}_{img_path.name}\"\n",
        "    cv2.imwrite(str(yolo/f\"images/{split_folder}/{name}\"), img)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segs = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 30:\n",
        "            c = cnt.flatten().astype(float)\n",
        "            c[0::2] /= w\n",
        "            c[1::2] /= h\n",
        "            segs.append(f\"0 {' '.join(map(str, c))}\")\n",
        "    if segs:\n",
        "        with open(yolo/f\"labels/{split_folder}/{name.replace('.tif','.txt')}\", \"w\") as f:\n",
        "            f.write(\"\\n\".join(segs))\n",
        "\n",
        "for p in tqdm(pairs[:split], desc=\"Train\"): convert(p[0], p[1], \"train\")\n",
        "for p in tqdm(pairs[split:], desc=\"Val\")  : convert(p[0], p[1], \"val\")\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as f:\n",
        "    f.write(\"\"\"path: yolo_dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "nc: 1\n",
        "names: ['tumor']\"\"\")\n",
        "\n",
        "print(\"YOLO dataset ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 5: ULTRA FAST GPU TRAINING (25–35 min)\n",
        "model = YOLO(\"yolov11n-seg.pt\")\n",
        "\n",
        "model.train(\n",
        "    data=\"data.yaml\",\n",
        "    epochs=80,\n",
        "    imgsz=224,\n",
        "    batch=16,\n",
        "    device=0,\n",
        "    project=\"runs\",\n",
        "    name=\"final\",\n",
        "    exist_ok=True,\n",
        "    patience=20,\n",
        "    amp=True,\n",
        "    workers=4\n",
        ")\n",
        "print(\"Training finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# STEP 6: Create demo video\n",
        "best = YOLO(\"runs/final/weights/best.pt\")\n",
        "imgs = sorted(list(Path(\"yolo_dataset/images/val\").glob(\"*.tif\")))[:30]\n",
        "\n",
        "frames = []\n",
        "for p in tqdm(imgs, desc=\"Video\"):\n",
        "    img = cv2.imread(str(p))\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = best(p, conf=0.25, verbose=False)[0]\n",
        "    overlay = img_rgb.copy()\n",
        "    if res.masks is not None:\n",
        "        for mask, box in zip(res.masks.data.cpu(), res.boxes.data.cpu()):\n",
        "            m = cv2.resize(mask.numpy(), overlay.shape[:2][::-1]) > 0.5\n",
        "            overlay[m] = overlay[m] * 0.6 + np.array([0,191,255]) * 0.4\n",
        "            cv2.putText(overlay, f\"Tumor {box[4]:.2f}\", (50,80), 1, 2, (255,255,255), 4)\n",
        "    cv2.putText(overlay, \"YOLOv11-seg LGG MRI | Omid Sakaki\", (20,img_rgb.shape[0]-30), 1, 0.9, (255,255,255), 2)\n",
        "    frames.append(overlay)\n",
        "\n",
        "out = cv2.VideoWriter(\"Demo.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), 6, (img_rgb.shape[1], img_rgb.shape[0]))\n",
        "for f in frames: out.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
        "out.release()\n",
        "\n",
        "display(FileLink(\"Demo.mp4\"))\n",
        "print(\"ALL DONE! Click the link to download your video\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
