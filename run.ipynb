{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv11-seg LGG MRI Tumor Segmentation\n",       
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install -q torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q ultralytics opencv-python kaggle tqdm\n",
        "\n",
        "from IPython.display import FileLink, display, clear_output\n",
        "import os, cv2, numpy as np, random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "print(\"All packages installed successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Upload kaggle.json (GitHub Codespaces version)\n",
        "print(\"Please DRAG & DROP your kaggle.json file into the left file explorer\")\n",
        "print(\"Path should be: /workspaces/LGG-MRI-YOLO-project/kaggle.json\")\n",
        "print(\"After dropping, run this cell again\")\n",
        "\n",
        "clear_output(wait=True)\n",
        "\n",
        "if not os.path.exists(\"kaggle.json\"):\n",
        "    print(\"kaggle.json not found! Please upload it first.\")\n",
        "else:\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(\"kaggle.json successfully installed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation\n",
        "!unzip -qo lgg-mri-segmentation.zip -d data\n",
        "print(\"Dataset downloaded and extracted!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Convert masks to YOLO segmentation format\n",
        "raw = Path(\"data/lgg-mri-segmentation\")\n",
        "yolo = Path(\"yolo_dataset\")\n",
        "for p in [\"images/train\", \"images/val\", \"labels/train\", \"labels/val\"]:\n",
        "    (yolo/p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pairs = []\n",
        "for patient in raw.iterdir():\n",
        "    if patient.is_dir():\n",
        "        imgs = list(patient.glob(\"*[0-9].tif\"))\n",
        "        for img in imgs:\n",
        "            mask = patient / f\"{img.stem}_mask.tif\"\n",
        "            if mask.exists():\n",
        "                pairs.append((img, mask))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(pairs)\n",
        "split = int(0.8 * len(pairs))\n",
        "\n",
        "def convert(img_path, mask_path, split):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    mask = cv2.imread(str(mask_path), 0)\n",
        "    h, w = img.shape[:2]\n",
        "    name = f\"{img_path.parent.name}_{img_path.name}\"\n",
        "    cv2.imwrite(str(yolo/f\"images/{split}/{name}\"), img)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segs = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 30:\n",
        "            c = cnt.flatten().astype(float)\n",
        "            c[0::2] /= w\n",
        "            c[1::2] /= h\n",
        "            segs.append(f\"0 {' '.join(map(str, c))}\")\n",
        "    if segs:\n",
        "        with open(yolo/f\"labels/{split}/{name.replace('.tif','.txt')}\", \"w\") as f:\n",
        "            f.write(\"\\n\".join(segs))\n",
        "\n",
        "for p in tqdm(pairs[:split], desc=\"Train\"): convert(p[0], p[1], \"train\")\n",
        "for p in tqdm(pairs[split:], desc=\"Val\")  : convert(p[0], p[1], \"val\")\n",
        "\n",
        "print(\"Conversion completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create data.yaml\n",
        "with open(\"data.yaml\", \"w\") as f:\n",
        "    f.write(\"\"\"path: yolo_dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "nc: 1\n",
        "names: ['tumor']\"\"\")\n",
        "print(\"data.yaml created!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train YOLOv11s-seg (low heat, high accuracy)\n",
        "model = YOLO(\"yolov11s-seg.pt\")\n",
        "model.train(\n",
        "    data=\"data.yaml\",\n",
        "    epochs=120,\n",
        "    imgsz=256,\n",
        "    batch=32,\n",
        "    device=0,\n",
        "    project=\"runs\",\n",
        "    name=\"lgg_mri\",\n",
        "    exist_ok=True,\n",
        "    patience=30,\n",
        "    pretrained=True,\n",
        "    close_mosaic=10,\n",
        "    freeze=10\n",
        ")\n",
        "print(\"Training finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create 30-frame professional demo video\n",
        "best = YOLO(\"runs/lgg_mri/weights/best.pt\")\n",
        "val_imgs = sorted(list(Path(\"yolo_dataset/images/val\").glob(\"*.tif\")))[:30]\n",
        "\n",
        "frames = []\n",
        "for p in tqdm(val_imgs, desc=\"Creating video\"):\n",
        "    img = cv2.imread(str(p))\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = best(p, conf=0.25, verbose=False)[0]\n",
        "    overlay = img_rgb.copy()\n",
        "    if res.masks is not None:\n",
        "        for mask, box in zip(res.masks.data.cpu(), res.boxes.data.cpu()):\n",
        "            m = cv2.resize(mask.numpy(), (img_rgb.shape[1], img_rgb.shape[0])) > 0.5\n",
        "            overlay[m] = overlay[m] * 0.6 + np.array([0,191,255]) * 0.4\n",
        "            cv2.putText(overlay, f\"Tumor {box[4]:.2f}\", (50,80),\n",
        "                       cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 4)\n",
        "    cv2.putText(overlay, \"YOLOv11-seg LGG MRI | Omid Sakaki\", (20,img_rgb.shape[0]-30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
        "    frames.append(overlay)\n",
        "\n",
        "out = cv2.VideoWriter(\"LGG_MRI_Demo.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), 6,\n",
        "                     (img_rgb.shape[1], img_rgb.shape[0]))\n",
        "for f in frames:\n",
        "    out.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
        "out.release()\n",
        "\n",
        "display(FileLink(\"LGG_MRI_Demo.mp4\"))\n",
        "print(\"All done! Click the link above to download your professional demo video\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
