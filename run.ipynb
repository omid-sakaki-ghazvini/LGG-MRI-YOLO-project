{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv11 LGG MRI Tumor Segmentation\n",
        "**Just upload your kaggle.json when asked**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install -q torch torchvision ultralytics opencv-python kaggle tqdm ipython\n",
        "\n",
        "from IPython.display import FileLink, display\n",
        "from google.colab import files\n",
        "import os, cv2, numpy as np, random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "\n",
        "# Upload kaggle.json\n",
        "print(\"Upload your kaggle.json (Kaggle → Account → Create New Token)\")\n",
        "uploaded = files.upload()\n",
        "!mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "# Download dataset\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation\n",
        "!unzip -qo lgg-mri-segmentation.zip -d data\n",
        "\n",
        "# Convert to YOLO format\n",
        "raw = Path(\"data/lgg-mri-segmentation\")\n",
        "yolo = Path(\"yolo_dataset\")\n",
        "for p in [\"images/train\",\"images/val\",\"labels/train\",\"labels/val\"]: (yolo/p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pairs = []\n",
        "for patient in raw.iterdir():\n",
        "    if patient.is_dir():\n",
        "        imgs = list(patient.glob(\"*[0-9].tif\"))\n",
        "        for img in imgs:\n",
        "            mask = patient / f\"{img.stem}_mask.tif\"\n",
        "            if mask.exists(): pairs.append((img, mask))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(pairs)\n",
        "split = int(0.8 * len(pairs))\n",
        "\n",
        "def convert(img_path, mask_path, split):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    mask = cv2.imread(str(mask_path), 0)\n",
        "    h, w = img.shape[:2]\n",
        "    name = f\"{img_path.parent.name}_{img_path.name}\"\n",
        "    cv2.imwrite(str(yolo/f\"images/{split}/{name}\"), img)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segs = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 30:\n",
        "            c = cnt.flatten().astype(float)\n",
        "            c[0::2] /= w\n",
        "            c[1::2] /= h\n",
        "            segs.append(f\"0 {' '.join(map(str, c))}\")\n",
        "    if segs:\n",
        "        with open(yolo/f\"labels/{split}/{name.replace('.tif','.txt')}\", \"w\") as f:\n",
        "            f.write(\"\\n\".join(segs))\n",
        "\n",
        "for p in tqdm(pairs[:split], desc=\"Train\"): convert(p[0], p[1], \"train\")\n",
        "for p in tqdm(pairs[split:], desc=\"Val\"):   convert(p[0], p[1], \"val\")\n",
        "\n",
        "# data.yaml\n",
        "with open(\"data.yaml\",\"w\") as f:\n",
        "    f.write(\"\"\"path: yolo_dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "nc: 1\n",
        "names: ['tumor']\"\"\")\n",
        "\n",
        "# Train\n",
        "model = YOLO(\"yolov11s-seg.pt\")\n",
        "model.train(data=\"data.yaml\", epochs=120, imgsz=256, batch=32, device=0,\n",
        "            project=\"runs\", name=\"lgg\", exist_ok=True, patience=30, close_mosaic=10, freeze=10)\n",
        "\n",
        "# Demo video\n",
        "best = YOLO(\"runs/lgg/weights/best.pt\")\n",
        "val_imgs = sorted(list(Path(\"yolo_dataset/images/val\").glob(\"*.tif\")))[:30]\n",
        "frames = []\n",
        "for p in tqdm(val_imgs, desc=\"Video\"):\n",
        "    img = cv2.imread(str(p))\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = best(p, conf=0.25, verbose=False)[0]\n",
        "    overlay = img_rgb.copy()\n",
        "    if res.masks is not None:\n",
        "        for mask, box in zip(res.masks.data.cpu(), res.boxes.data.cpu()):\n",
        "            m = cv2.resize(mask.numpy(), (img_rgb.shape[1], img_rgb.shape[0])) > 0.5\n",
        "            overlay[m] = overlay[m] * 0.6 + np.array([0,191,255]) * 0.4\n",
        "            cv2.putText(overlay, f\"Tumor {box[4]:.2f}\", (50,80), cv2.FONT_HERSHEY_SIMPLEX, 2, (255,255,255), 4)\n",
        "    cv2.putText(overlay, \"YOLOv11-seg LGG MRI | Omid Sakaki\", (20,img_rgb.shape[0]-20),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.9, (255,255,255), 2)\n",
        "    frames.append(overlay)\n",
        "\n",
        "out = cv2.VideoWriter(\"Demo.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), 6, (img_rgb.shape[1], img_rgb.shape[0]))\n",
        "for f in frames: out.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
        "out.release()\n",
        "\n",
        "display(FileLink(\"Demo.mp4\"))\n",
        "print(\"All done! Click the link above to download your video\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
