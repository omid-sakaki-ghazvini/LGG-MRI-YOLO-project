{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv11-seg LGG MRI Tumor Segmentation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 1: Install correct & compatible versions (fixes CUDA + YOLOv11)\n",
        "!pip install -q --no-cache-dir --force-reinstall torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q --no-cache-dir --force-reinstall ultralytics --no-deps\n",
        "!pip install -q --no-cache-dir opencv-python-headless tqdm kaggle\n",
        "\n",
        "import torch\n",
        "from ultralytics import YOLO\n",
        "import os, cv2, numpy as np, random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from IPython.display import FileLink, display, clear_output\n",
        "\n",
        "print(\"Installation complete!\")\n",
        "print(f\"Ultralytics: {__import__('ultralytics').__version__}\")\n",
        "print(f\"PyTorch: {torch.__version__}\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 2: Upload kaggle.json (drag & drop into left panel)\n",
        "print(\"Please DRAG & DROP your kaggle.json file into the file explorer on the left\")\n",
        "print(\"Then re-run this cell\")\n",
        "clear_output(wait=True)\n",
        "\n",
        "if not os.path.exists(\"kaggle.json\"):\n",
        "    print(\"kaggle.json not found! Please upload it.\")\n",
        "else:\n",
        "    !mkdir -p ~/.kaggle\n",
        "    !cp kaggle.json ~/.kaggle/\n",
        "    !chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(\"kaggle.json configured successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 3: Download & extract LGG MRI dataset\n",
        "!rm -rf lgg-mri-segmentation lgg-mri-segmentation.zip 2>/dev/null || true\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation --unzip\n",
        "\n",
        "from pathlib import Path\n",
        "patients = [p for p in Path(\"lgg-mri-segmentation\").iterdir() if p.is_dir()]\n",
        "print(f\"Dataset ready → {len(patients)} patient folders found\")\n",
        "print(\"Example:\", patients[:3])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 4: Convert to YOLO segmentation format\n",
        "!rm -rf yolo_dataset 2>/dev/null || true\n",
        "\n",
        "raw = Path(\"lgg-mri-segmentation\")\n",
        "yolo = Path(\"yolo_dataset\")\n",
        "for p in [\"images/train\",\"images/val\",\"labels/train\",\"labels/val\"]:\n",
        "    (yolo/p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pairs = []\n",
        "for patient in raw.iterdir():\n",
        "    if patient.is_dir():\n",
        "        for img in patient.glob(\"*[0-9].tif\"):\n",
        "            mask = patient / f\"{img.stem}_mask.tif\"\n",
        "            if mask.exists():\n",
        "                pairs.append((img, mask))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(pairs)\n",
        "split = int(0.8 * len(pairs))\n",
        "\n",
        "def convert(img_path, mask_path, folder):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    mask = cv2.imread(str(mask_path), 0)\n",
        "    h, w = img.shape[:2]\n",
        "    name = f\"{img_path.parent.name}_{img_path.name}\"\n",
        "    cv2.imwrite(str(yolo/f\"images/{folder}/{name}\"), img)\n",
        "    \n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segs = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 30:\n",
        "            c = cnt.flatten().astype(float)\n",
        "            c[0::2] /= w\n",
        "            c[1::2] /= h\n",
        "            segs.append(f\"0 {' '.join(map(str, c))}\")\n",
        "    if segs:\n",
        "        with open(yolo/f\"labels/{folder}/{name.replace('.tif','.txt')}\", \"w\") as f:\n",
        "            f.write(\"\\n\".join(segs))\n",
        "\n",
        "for p in tqdm(pairs[:split], desc=\"Train\"): convert(p[0], p[1], \"train\")\n",
        "for p in tqdm(pairs[split:], desc=\"Val\")  : convert(p[0], p[1], \"val\")\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as f:\n",
        "    f.write(\"path: yolo_dataset\\ntrain: images/train\\nval: images/val\\nnc: 1\\nnames: ['tumor']\")\n",
        "\n",
        "print(\"YOLO dataset ready!\")\n",
        "print(f\"Train images: {len(list((yolo/'images/train').glob('*.tif')))}\")\n",
        "print(f\"Val images: {len(list((yolo/'images/val').glob('*.tif')))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 5: Train YOLOv11-seg on GPU (~25–35 min)\n",
        "model = YOLO(\"yolov11n-seg.pt\")  # auto-downloads first time\n",
        "\n",
        "model.train(\n",
        "    data=\"data.yaml\",\n",
        "    epochs=80,\n",
        "    imgsz=256,\n",
        "    batch=32,\n",
        "    device=0,\n",
        "    project=\"runs\",\n",
        "    name=\"yolov11_lgg\",\n",
        "    exist_ok=True,\n",
        "    amp=True,\n",
        "    patience=20,\n",
        "    workers=4,\n",
        "    seed=42\n",
        ")\n",
        "print(\"Training completed!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# CELL 6: Generate 30-frame professional demo video\n",
        "best = YOLO(\"runs/yolov11_lgg/weights/best.pt\")\n",
        "val_imgs = sorted(list(Path(\"yolo_dataset/images/val\").glob(\"*.tif\")))[:30]\n",
        "\n",
        "frames = []\n",
        "for p in tqdm(val_imgs, desc=\"Creating demo video\"):\n",
        "    img = cv2.imread(str(p))\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = best(p, conf=0.3, verbose=False)[0]\n",
        "    overlay = img_rgb.copy()\n",
        "    \n",
        "    if res.masks is not None:\n",
        "        for mask in res.masks.data.cpu():\n",
        "            m = cv2.resize((mask.numpy() > 0.5).astype(np.uint8), (img.shape[1], img.shape[0]))\n",
        "            overlay = np.where(m[...,None], overlay*0.6 + np.array([0,200,255])*0.4, overlay)\n",
        "    \n",
        "    cv2.putText(overlay, \"YOLOv11-seg | LGG MRI Tumor Segmentation\", (20, 40),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255,255,255), 2)\n",
        "    cv2.putText(overlay, \"Omid Sakaki\", (20, img_rgb.shape[0]-20),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.7, (200,255,255), 2)\n",
        "    \n",
        "    frames.append(overlay)\n",
        "\n",
        "out = cv2.VideoWriter(\"LGG_MRI_YOLOv11_Demo.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), 6, (img_rgb.shape[1], img_rgb.shape[0]))\n",
        "for f in frames:\n",
        "    out.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
        "out.release()\n",
        "\n",
        "display(FileLink(\"LGG_MRI_YOLOv11_Demo.mp4\"))\n",
        "print(\"ALL DONE! Click the link above to download your professional demo video!\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
