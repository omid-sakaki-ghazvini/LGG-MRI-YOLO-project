{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# YOLOv11-seg LGG MRI\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 1. Install everything THE RIGHT WAY (fixes libGL forever)\n",
        "!pip install -q --no-cache-dir torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118\n",
        "!pip install -q --no-cache-dir ultralytics kaggle tqdm\n",
        "\n",
        "# THIS LINE IS THE REAL FIX – conda-forge headless OpenCV (no GUI deps)\n",
        "!pip install -q --no-cache-dir -f https://repo.anaconda.com/pkgs/main/ opencv-python-headless\n",
        "\n",
        "import torch, os, cv2, numpy as np, random\n",
        "from pathlib import Path\n",
        "from tqdm import tqdm\n",
        "from ultralytics import YOLO\n",
        "from IPython.display import FileLink, display, clear_output\n",
        "\n",
        "print(\"All packages installed – NO MORE libGL ERROR!\")\n",
        "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 2. Upload kaggle.json (drag & drop into left panel)\n",
        "print(\"DRAG & DROP kaggle.json here → then run this cell again\")\n",
        "clear_output(wait=True)\n",
        "if not os.path.exists(\"kaggle.json\"):\n",
        "    print(\"kaggle.json not found! Please upload it.\")\n",
        "else:\n",
        "    !mkdir -p ~/.kaggle && cp kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json\n",
        "    print(\"kaggle.json ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 3. Download dataset\n",
        "!kaggle datasets download -d mateuszbuda/lgg-mri-segmentation\n",
        "!unzip -qo lgg-mri-segmentation.zip -d data\n",
        "print(\"Dataset ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 4. Convert to YOLO format + create data.yaml\n",
        "raw = Path(\"data/lgg-mri-segmentation\")\n",
        "yolo = Path(\"yolo_dataset\")\n",
        "for p in [\"images/train\",\"images/val\",\"labels/train\",\"labels/val\"]:\n",
        "    (yolo/p).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "pairs = []\n",
        "for patient in raw.iterdir():\n",
        "    if patient.is_dir():\n",
        "        for img in patient.glob(\"*[0-9].tif\"):\n",
        "            mask = patient / f\"{img.stem}_mask.tif\"\n",
        "            if mask.exists():\n",
        "                pairs.append((img, mask))\n",
        "\n",
        "random.seed(42)\n",
        "random.shuffle(pairs)\n",
        "split = int(0.8*len(pairs))\n",
        "\n",
        "def convert(img_path, mask_path, folder):\n",
        "    img = cv2.imread(str(img_path))\n",
        "    mask = cv2.imread(str(mask_path), 0)\n",
        "    h, w = img.shape[:2]\n",
        "    name = f\"{img_path.parent.name}_{img_path.name}\"\n",
        "    cv2.imwrite(str(yolo/f\"images/{folder}/{name}\"), img)\n",
        "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    segs = []\n",
        "    for cnt in contours:\n",
        "        if cv2.contourArea(cnt) > 30:\n",
        "            c = cnt.flatten().astype(float)\n",
        "            c[0::2] /= w\n",
        "            c[1::2] /= h\n",
        "            segs.append(f\"0 {' '.join(map(str, c))}\")\n",
        "    if segs:\n",
        "        with open(yolo/f\"labels/{folder}/{name.replace('.tif','.txt')}\", \"w\") as f:\n",
        "            f.write(\"\\n\".join(segs))\n",
        "\n",
        "for p in tqdm(pairs[:split], desc=\"Train\"): convert(p[0], p[1], \"train\")\n",
        "for p in tqdm(pairs[split:], desc=\"Val\")  : convert(p[0], p[1], \"val\")\n",
        "\n",
        "with open(\"data.yaml\", \"w\") as f:\n",
        "    f.write(\"path: yolo_dataset\\ntrain: images/train\\nval: images/val\\nnc: 1\\nnames: ['tumor']\")\n",
        "\n",
        "print(\"YOLO dataset ready!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 5. ULTRA-FAST GPU TRAINING (~25–35 min)\n",
        "model = YOLO(\"yolov11n-seg.pt\")   # auto-downloads first time\n",
        "\n",
        "model.train(\n",
        "    data=\"data.yaml\",\n",
        "    epochs=70,\n",
        "    imgsz=224,\n",
        "    batch=16,\n",
        "    device=0 if torch.cuda.is_available() else \"cpu\",\n",
        "    project=\"runs\",\n",
        "    name=\"final\",\n",
        "    exist_ok=True,\n",
        "    amp=True,\n",
        "    patience=15,\n",
        "    workers=4\n",
        ")\n",
        "print(\"Training finished!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 6. Create beautiful 30-frame demo video\n",
        "best = YOLO(\"runs/final/weights/best.pt\")\n",
        "imgs = sorted(list(Path(\"yolo_dataset/images/val\").glob(\"*.tif\")))[:30]\n",
        "\n",
        "frames = []\n",
        "for p in tqdm(imgs, desc=\"Making video\"):\n",
        "    img = cv2.imread(str(p))\n",
        "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "    res = best(p, conf=0.3, verbose=False)[0]\n",
        "    overlay = img_rgb.copy()\n",
        "    if res.masks is not None:\n",
        "        for mask in res.masks.data.cpu():\n",
        "            m = cv2.resize((mask.numpy() > 0.5).astype(np.uint8), (img.shape[1], img.shape[0]))\n",
        "            overlay = np.where(m[...,None], overlay*0.6 + np.array([0,191,255])*0.4, overlay)\n",
        "    cv2.putText(overlay, \"YOLOv11-seg LGG MRI | Omid Sakaki\", (20, img_rgb.shape[0]-20),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255,255,255), 2)\n",
        "    frames.append(overlay)\n",
        "\n",
        "out = cv2.VideoWriter(\"Demo.mp4\", cv2.VideoWriter_fourcc(*\"mp4v\"), 5, (img_rgb.shape[1], img_rgb.shape[0]))\n",
        "for f in frames:\n",
        "    out.write(cv2.cvtColor(f, cv2.COLOR_RGB2BGR))\n",
        "out.release()\n",
        "\n",
        "display(FileLink(\"Demo.mp4\"))\n",
        "print(\"FINISHED! Click the link above to download your video\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
